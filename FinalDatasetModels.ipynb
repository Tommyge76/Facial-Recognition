{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalDatasetModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL3qW6hR8PIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9370819-2889-41ea-f1e1-e5a14171faf5"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import copy\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "## Folder path for the UTK image dataset\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/UTKFace/'\n",
        "\n",
        "## Paths for the npy files created for ease\n",
        "\n",
        "images_path = '/content/drive/MyDrive/FaceFiles/images_full.npy'\n",
        "\n",
        "ages_path = '/content/drive/MyDrive/FaceFiles/ages_full.npy'\n",
        "\n",
        "genders_path = '/content/drive/MyDrive/FaceFiles/genders_full.npy'\n",
        "\n",
        "races_path = '/content/drive/MyDrive/FaceFiles/races_full.npy'\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    ages = []\n",
        "    genders = []\n",
        "    races = []\n",
        "    dates = []\n",
        "    for filename in os.listdir(folder):\n",
        "        print(filename)\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "          if (len(filename.split('_')) == 4):\n",
        "            age, gender, race, date = filename_data(filename)\n",
        "            images.append(img)\n",
        "            ages.append(age)\n",
        "            genders.append(gender)\n",
        "            races.append(race)\n",
        "            dates.append(date)\n",
        "    return images, ages, genders, races, dates\n",
        "\n",
        "\n",
        "def filename_data(filename):\n",
        "  img_name = filename\n",
        "  data = img_name.split('_')\n",
        "  age = data[0]\n",
        "  gender = data[1]\n",
        "  race = data[2]\n",
        "  data2 = data[3]\n",
        "  date = data2.split('.')[0]\n",
        "  return age, gender, race, date\n",
        "def get_accuracy(predicted, actual):\n",
        "  n = len(predicted)\n",
        "  tot = 0\n",
        "  for i in range(n):\n",
        "    if predicted[i] == actual[i]:\n",
        "      tot = tot + 1\n",
        "  return tot/n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXw2atWithSG"
      },
      "source": [
        "# Saving and Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqo2-9g6QDaH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0e3d6a64-a36e-4420-da27-90cbac900ed8"
      },
      "source": [
        "## This is just to save the data for later so loading isn't required every time\n",
        "## Don't run if you already have the data in the .npy files\n",
        "images, ages, genders, races, dates = load_images_from_folder(folder_path)\n",
        "np.save('images.npy', images)\n",
        "np.save('ages.npy', ages)\n",
        "np.save('genders.npy', genders)\n",
        "np.save('races.npy', races)\n",
        "np.save('dates.npy', dates)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-745ec6550da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## This is just to save the data for later so loading isn't required every time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Don't run if you already have the data in the .npy files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ages.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5ab7d27ccc54>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mraces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UTKFace/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kozTFhIgIj5u"
      },
      "source": [
        "## Loading\n",
        "images = np.load(images_path)\n",
        "ages = np.load(ages_path)\n",
        "genders = np.load(genders_path)\n",
        "races = np.load(races_path)\n",
        "#dates = np.load(dates_path)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k7if9TcuAB7"
      },
      "source": [
        "# Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5vAwie48gr-"
      },
      "source": [
        "## gender: 0=male, 1=female\n",
        "## race: 0=white, 1=black, 2=asian, 3=indian\n",
        "## n = 23705\n",
        "## Balance models n = 10824, all = 2706\n",
        "## Gender_full n = 18964, w = 8091, b = 3652, a = 2706, i = 3172, o = 1343\n",
        "## Race_full n = 17621, w = 8091, b = 3652, a = 2706, i = 3172\n",
        "genders = genders.astype(np.uint8)\n",
        "races = races.astype(np.uint8)\n",
        "\n",
        "random.seed(1)\n",
        "trn_idx = random.sample(range(23705), round(23705*.8))\n",
        "\n",
        "trn_bool = [False] * 23705\n",
        "\n",
        "for i in trn_idx:\n",
        "  trn_bool[i] = True\n",
        "\n",
        "tst_bool = np.invert(trn_bool)\n",
        "\n",
        "races_trn = races[trn_bool]\n",
        "races_tst = races[tst_bool]\n",
        "img_trn = images[trn_bool]\n",
        "img_tst = images[tst_bool]\n",
        "gender_trn = genders[trn_bool]\n",
        "gender_tst = genders[tst_bool]\n",
        "\n",
        "del images\n",
        "\n",
        "white = races == 0\n",
        "black = races == 1\n",
        "asian = races == 2\n",
        "indian = races == 3\n",
        "other = races == 4\n",
        "\n",
        "four_race_trn = races_trn != 4\n",
        "\n",
        "n_male = sum(genders == 0)\n",
        "n_female = sum(genders == 1)\n",
        "\n",
        "n_white = len(genders[white])\n",
        "n_black = len(genders[black])\n",
        "n_asian = len(genders[asian])\n",
        "n_indian = len(genders[indian])\n",
        "n_other = len(genders[other])\n",
        "n_tot = len(genders)\n",
        "\n",
        "white_genders = genders[white]\n",
        "black_genders = genders[black]\n",
        "asian_genders = genders[asian]\n",
        "indian_genders = genders[indian]\n",
        "other_genders = genders[other]\n",
        "\n",
        "\n",
        "white_trn = races_trn == 0\n",
        "black_trn = races_trn == 1\n",
        "asian_trn = races_trn == 2\n",
        "indian_trn = races_trn == 3\n",
        "n_w_trn = sum(white_trn)\n",
        "n_b_trn = sum(black_trn)\n",
        "n_a_trn = sum(asian_trn)\n",
        "n_i_trn = sum(indian_trn)\n",
        "min_n = min(n_w_trn, n_b_trn, n_a_trn, n_i_trn)\n",
        "\n",
        "\n",
        "white_img_trn = img_trn[white_trn]\n",
        "white_gender_trn = gender_trn[white_trn]\n",
        "white_race_trn = races_trn[white_trn]\n",
        "random.seed(101)\n",
        "whiteTrnIdx2 = random.sample(range(n_w_trn), min_n)\n",
        "whiteImgTrn2 = white_img_trn[whiteTrnIdx2]\n",
        "whiteGenderTrn2 = white_gender_trn[whiteTrnIdx2]\n",
        "whiteRaceTrn2 = white_race_trn[whiteTrnIdx2]\n",
        "\n",
        "\n",
        "black_img_trn = img_trn[black_trn]\n",
        "black_gender_trn = gender_trn[black_trn]\n",
        "black_race_trn = races_trn[black_trn]\n",
        "random.seed(102)\n",
        "blackTrnIdx2 = random.sample(range(n_b_trn), min_n)\n",
        "blackImgTrn2 = black_img_trn[blackTrnIdx2]\n",
        "blackGenderTrn2 = black_gender_trn[blackTrnIdx2]\n",
        "blackRaceTrn2 = black_race_trn[blackTrnIdx2]\n",
        "\n",
        "\n",
        "asian_img_trn = img_trn[asian_trn]\n",
        "asian_gender_trn = gender_trn[asian_trn]\n",
        "asian_race_trn = races_trn[asian_trn]\n",
        "random.seed(103)\n",
        "asianTrnIdx2 = random.sample(range(n_a_trn), min_n)\n",
        "asianImgTrn2 = black_img_trn[asianTrnIdx2]\n",
        "asianGenderTrn2 = asian_gender_trn[asianTrnIdx2]\n",
        "asianRaceTrn2 = asian_race_trn[asianTrnIdx2]\n",
        "\n",
        "\n",
        "indian_img_trn = img_trn[indian_trn]\n",
        "indian_gender_trn = gender_trn[indian_trn]\n",
        "indian_race_trn = races_trn[indian_trn]\n",
        "random.seed(104)\n",
        "indianTrnIdx2 = random.sample(range(n_i_trn), min_n)\n",
        "indianImgTrn2 = indian_img_trn[indianTrnIdx2]\n",
        "indianGenderTrn2 = indian_gender_trn[indianTrnIdx2]\n",
        "indianRaceTrn2 = indian_race_trn[indianTrnIdx2]\n",
        "\n",
        "\n",
        "imgTrnBalance = np.concatenate((whiteImgTrn2, blackImgTrn2, asianImgTrn2, indianImgTrn2))\n",
        "genderTrnBalance = np.concatenate((whiteGenderTrn2, blackGenderTrn2, asianGenderTrn2, indianGenderTrn2))\n",
        "raceTrnBalance = np.concatenate((whiteRaceTrn2, blackRaceTrn2, asianRaceTrn2, indianRaceTrn2))\n",
        "del whiteImgTrn2\n",
        "del blackImgTrn2\n",
        "del asianImgTrn2\n",
        "del indianImgTrn2\n",
        "del white_img_trn\n",
        "del black_img_trn\n",
        "del asian_img_trn\n",
        "del indian_img_trn"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YADVdXdOuWy_"
      },
      "source": [
        "# Graphs for Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZlcPoyoubje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "2e5c760d-d8bb-4338-a156-679689879ef8"
      },
      "source": [
        "## racial distribution\n",
        "import matplotlib.pyplot as plt\n",
        "race_pie  = np.array([n_white, n_black, n_indian, n_asian, n_other])\n",
        "label = ['White(42.5%)', 'Black(19.1%)', 'Indian(16.8%)', 'Asian(14.5%)', 'Other(7.1%)']\n",
        "plt.title('Distribution of Race for the Entire Dataset')\n",
        "plt.pie(race_pie, labels = label)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t3SfQ-IucEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "e73c7496-6fae-44f7-efba-3fafa7111919"
      },
      "source": [
        "## gender distribution\n",
        "gender_pie = np.array([n_male, n_female])\n",
        "plt.title('Distribution of Gender for the Entire Dataset')\n",
        "plt.pie(gender_pie, labels = ['Male(52.3%)', 'Female(47.7%)'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.patches.Wedge at 0x7fb2ed4c2f10>,\n",
              "  <matplotlib.patches.Wedge at 0x7fb2ed4d1390>],\n",
              " [Text(-0.07843666139757915, 1.097199931711993, 'Male(52.3%)'),\n",
              "  Text(0.07843655867030727, -1.0971999390557583, 'Female(47.7%)')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqPCLy-U1qQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "4c4f2a74-0e8a-41f1-e435-febde99fa4e3"
      },
      "source": [
        "## 4 race gender dist plots\n",
        "fig, axes = plt.subplots(2,2)\n",
        "\n",
        "w_m = sum(white_genders == 0)\n",
        "w_f = sum(white_genders == 1)\n",
        "m_per = round(100*w_m/n_white,1)\n",
        "f_per = round(100*w_f/n_white,1)\n",
        "gender_pie = np.array([w_m, w_f])\n",
        "axes[0,0].set_title('Gender Dist for White')\n",
        "axes[0,0].pie(gender_pie, labels = [f'Male({m_per}%)', f'Female({f_per}%)'])\n",
        "\n",
        "\n",
        "b_m = sum(black_genders == 0)\n",
        "b_f = sum(black_genders == 1)\n",
        "m_per = round(100*b_m/n_black,1)\n",
        "f_per = round(100*b_f/n_black,1)\n",
        "gender_pie = np.array([b_m, b_f])\n",
        "axes[0,1].set_title('Gender Dist for Black')\n",
        "axes[0,1].pie(gender_pie, labels = [f'Male({m_per}%)', f'Female({f_per}%)'])\n",
        "\n",
        "\n",
        "a_m = sum(asian_genders == 0)\n",
        "a_f = sum(asian_genders == 1)\n",
        "m_per = round(100*a_m/n_asian,1)\n",
        "f_per = round(100*a_f/n_asian,1)\n",
        "gender_pie = np.array([a_m, a_f])\n",
        "axes[1,0].set_title('Gender Dist for Asian')\n",
        "axes[1,0].pie(gender_pie, labels = [f'Male({m_per}%)', f'Female({f_per}%)'])\n",
        "\n",
        "\n",
        "i_m = sum(indian_genders == 0)\n",
        "i_f = sum(indian_genders == 1)\n",
        "m_per = round(100*i_m/n_indian,1)\n",
        "f_per = round(100*i_f/n_indian,1)\n",
        "gender_pie = np.array([i_m, i_f])\n",
        "axes[1,1].set_title('Gender Dist for Indian')\n",
        "axes[1,1].pie(gender_pie, labels = [f'Male({m_per}%)', f'Female({f_per}%)'])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhFLa6mNE-f1"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grQExmMw8kN7"
      },
      "source": [
        "## This is the model for gender classification\n",
        "def createGenderModel():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## Sigmoid for binary classification\n",
        "  model.add(\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "## This is the model for race classification\n",
        "def createRaceModel():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## softmax for catagorical classification(might need to change to 4 and not include other as gender)\n",
        "  model.add(\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'catagorical_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1vKoVOdIVqK"
      },
      "source": [
        "# Model Training and diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "c3As6AzNIecw",
        "outputId": "38b5faab-6f1f-4536-cd08-2986d70da584"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-ad76bfb4e896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6VkU7QL3YxJ"
      },
      "source": [
        "gender_model = createGenderModel()\n",
        "gender_model_balance = createGenderModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmFqbL2QZHft",
        "outputId": "5266faee-0620-4fc3-bf8d-5e6a0d692e9b"
      },
      "source": [
        "gender_model_history = gender_model.fit(img_trn, gender_trn, epochs = 50)\n",
        "gender_model_balance_history = gender_model_balance.fit(imgTrnBalance, genderTrnBalance, epochs = 50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 59s 48ms/step - loss: 3.2284 - accuracy: 0.5682\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.5769 - accuracy: 0.7086\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.4950 - accuracy: 0.7728\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.4463 - accuracy: 0.7998\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.4209 - accuracy: 0.8112\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3952 - accuracy: 0.8250\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3771 - accuracy: 0.8374\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3681 - accuracy: 0.8356\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3566 - accuracy: 0.8449\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3369 - accuracy: 0.8500\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3315 - accuracy: 0.8536\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3196 - accuracy: 0.8595\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3204 - accuracy: 0.8604\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3162 - accuracy: 0.8601\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3121 - accuracy: 0.8635\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 0.2989 - accuracy: 0.8686\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.3059 - accuracy: 0.8624\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2990 - accuracy: 0.8647\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2953 - accuracy: 0.8715\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2977 - accuracy: 0.8708\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2751 - accuracy: 0.8776\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2785 - accuracy: 0.8776\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2869 - accuracy: 0.8720\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2804 - accuracy: 0.8797\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2764 - accuracy: 0.8787\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2782 - accuracy: 0.8819\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2705 - accuracy: 0.8818\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2723 - accuracy: 0.8792\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2715 - accuracy: 0.8793\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2643 - accuracy: 0.8830\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2598 - accuracy: 0.8906\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2630 - accuracy: 0.8836\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2637 - accuracy: 0.8829\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2627 - accuracy: 0.8901\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2519 - accuracy: 0.8902\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2457 - accuracy: 0.8935\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2538 - accuracy: 0.8911\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2439 - accuracy: 0.8936\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2439 - accuracy: 0.8936\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2501 - accuracy: 0.8919\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2325 - accuracy: 0.9011\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2459 - accuracy: 0.8938\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2444 - accuracy: 0.8945\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2418 - accuracy: 0.8976\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2371 - accuracy: 0.8987\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2379 - accuracy: 0.9005\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2374 - accuracy: 0.8981\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2282 - accuracy: 0.9030\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2280 - accuracy: 0.9020\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 28s 47ms/step - loss: 0.2364 - accuracy: 0.8983\n",
            "Epoch 1/50\n",
            "339/339 [==============================] - 17s 48ms/step - loss: 3.6348 - accuracy: 0.5351\n",
            "Epoch 2/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.6835 - accuracy: 0.5942\n",
            "Epoch 3/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.6417 - accuracy: 0.6377\n",
            "Epoch 4/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.6174 - accuracy: 0.6690\n",
            "Epoch 5/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.6076 - accuracy: 0.6840\n",
            "Epoch 6/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5777 - accuracy: 0.7108\n",
            "Epoch 7/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5660 - accuracy: 0.7260\n",
            "Epoch 8/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5661 - accuracy: 0.7244\n",
            "Epoch 9/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5536 - accuracy: 0.7343\n",
            "Epoch 10/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5496 - accuracy: 0.7297\n",
            "Epoch 11/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5460 - accuracy: 0.7400\n",
            "Epoch 12/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5387 - accuracy: 0.7483\n",
            "Epoch 13/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5355 - accuracy: 0.7518\n",
            "Epoch 14/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5252 - accuracy: 0.7592\n",
            "Epoch 15/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5260 - accuracy: 0.7573\n",
            "Epoch 16/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5225 - accuracy: 0.7586\n",
            "Epoch 17/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5154 - accuracy: 0.7664\n",
            "Epoch 18/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.5147 - accuracy: 0.7671\n",
            "Epoch 19/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5078 - accuracy: 0.7645\n",
            "Epoch 20/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5059 - accuracy: 0.7674\n",
            "Epoch 21/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.5085 - accuracy: 0.7664\n",
            "Epoch 22/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4962 - accuracy: 0.7750\n",
            "Epoch 23/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4966 - accuracy: 0.7750\n",
            "Epoch 24/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4852 - accuracy: 0.7825\n",
            "Epoch 25/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4839 - accuracy: 0.7844\n",
            "Epoch 26/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4885 - accuracy: 0.7784\n",
            "Epoch 27/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4901 - accuracy: 0.7794\n",
            "Epoch 28/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4764 - accuracy: 0.7888\n",
            "Epoch 29/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4806 - accuracy: 0.7877\n",
            "Epoch 30/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4811 - accuracy: 0.7845\n",
            "Epoch 31/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4816 - accuracy: 0.7843\n",
            "Epoch 32/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4727 - accuracy: 0.7871\n",
            "Epoch 33/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4647 - accuracy: 0.7956\n",
            "Epoch 34/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4655 - accuracy: 0.7935\n",
            "Epoch 35/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4764 - accuracy: 0.7876\n",
            "Epoch 36/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4710 - accuracy: 0.7911\n",
            "Epoch 37/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4625 - accuracy: 0.7967\n",
            "Epoch 38/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4668 - accuracy: 0.7881\n",
            "Epoch 39/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4538 - accuracy: 0.8013\n",
            "Epoch 40/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4598 - accuracy: 0.7901\n",
            "Epoch 41/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4513 - accuracy: 0.7955\n",
            "Epoch 42/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4546 - accuracy: 0.8040\n",
            "Epoch 43/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4471 - accuracy: 0.7970\n",
            "Epoch 44/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4498 - accuracy: 0.7988\n",
            "Epoch 45/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 0.4529 - accuracy: 0.8001\n",
            "Epoch 46/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4485 - accuracy: 0.7987\n",
            "Epoch 47/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4418 - accuracy: 0.8063\n",
            "Epoch 48/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4455 - accuracy: 0.7978\n",
            "Epoch 49/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4524 - accuracy: 0.7934\n",
            "Epoch 50/50\n",
            "339/339 [==============================] - 16s 47ms/step - loss: 0.4442 - accuracy: 0.8008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB0-WHcL-Q-y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ae9f5f83-9f36-49ed-86e9-4d286c523958"
      },
      "source": [
        "w_p_w = (white_model.predict(white_images_2) > 0.5).astype(\"int32\")\n",
        "w_p_b = (white_model.predict(black_images) > 0.5).astype(\"int32\")\n",
        "w_p_a = (white_model.predict(asian_images_2) > 0.5).astype(\"int32\")\n",
        "w_p_i = (white_model.predict(indian_images_2) > 0.5).astype(\"int32\")\n",
        "\n",
        "w = get_accuracy(w_p_w, white_genders_2)\n",
        "b = get_accuracy(w_p_b, black_genders)\n",
        "a = get_accuracy(w_p_a, asian_genders_2)\n",
        "i = get_accuracy(w_p_i, indian_genders_2)\n",
        "fig = plt.figure()\n",
        "labs = ['white', 'black', 'asian', 'indian']\n",
        "accuracies = [w,b,a,i]\n",
        "plt.bar(labs,accuracies)\n",
        "plt.ylabel('accuracies')\n",
        "plt.title('Prediction Accuracies of Model trained only on white faces')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-87adf986bf88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_p_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwhite_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhite_images_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mw_p_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwhite_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblack_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw_p_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwhite_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masian_images_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw_p_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwhite_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindian_images_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'white_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMlhC16J-RZ8"
      },
      "source": [
        "b_p_w = (black_model.predict(white_images_2) > 0.5).astype(\"int32\")\n",
        "b_p_b = (black_model.predict(black_images) > 0.5).astype(\"int32\")\n",
        "b_p_a = (black_model.predict(asian_images_2) > 0.5).astype(\"int32\")\n",
        "b_p_i = (black_model.predict(indian_images_2) > 0.5).astype(\"int32\")\n",
        "\n",
        "w = get_accuracy(b_p_w, white_genders_2)\n",
        "b = get_accuracy(b_p_b, black_genders)\n",
        "a = get_accuracy(b_p_a, asian_genders_2)\n",
        "i = get_accuracy(b_p_i, indian_genders_2)\n",
        "fig = plt.figure()\n",
        "labs = ['white', 'black', 'asian', 'indian']\n",
        "accuracies = [w,b,a,i]\n",
        "plt.bar(labs,accuracies)\n",
        "plt.ylabel('accuracies')\n",
        "plt.title('Prediction Accuracies of Model trained only on Black faces')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRdW9JkV-Rvc"
      },
      "source": [
        "a_p_w = (asian_model.predict(white_images_2) > 0.5).astype(\"int32\")\n",
        "a_p_b = (asian_model.predict(black_images) > 0.5).astype(\"int32\")\n",
        "a_p_a = (asian_model.predict(asian_images_2) > 0.5).astype(\"int32\")\n",
        "a_p_i = (asian_model.predict(indian_images_2) > 0.5).astype(\"int32\")\n",
        "\n",
        "w = get_accuracy(a_p_w, white_genders_2)\n",
        "b = get_accuracy(a_p_b, black_genders)\n",
        "a = get_accuracy(a_p_a, asian_genders_2)\n",
        "i = get_accuracy(a_p_i, indian_genders_2)\n",
        "fig = plt.figure()\n",
        "labs = ['white', 'black', 'asian', 'indian']\n",
        "accuracies = [w,b,a,i]\n",
        "plt.bar(labs,accuracies)\n",
        "plt.ylabel('accuracies')\n",
        "plt.title('Prediction Accuracies of Model trained only on Asian faces')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXc0auavI_Fi",
        "outputId": "798b5c27-1e0c-40fa-f387-864d38787ac2"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tD3jdrE-SOm"
      },
      "source": [
        "i_p_w = (indian_model.predict(white_images_2) > 0.5).astype(\"int32\")\n",
        "i_p_b = (indian_model.predict(black_images) > 0.5).astype(\"int32\")\n",
        "i_p_a = (indian_model.predict(asian_images_2) > 0.5).astype(\"int32\")\n",
        "i_p_i = (indian_model.predict(indian_images_2) > 0.5).astype(\"int32\")\n",
        "\n",
        "w = get_accuracy(i_p_w, white_genders_2)\n",
        "b = get_accuracy(i_p_b, black_genders)\n",
        "a = get_accuracy(i_p_a, asian_genders_2)\n",
        "i = get_accuracy(i_p_i, indian_genders_2)\n",
        "fig = plt.figure()\n",
        "labs = ['white', 'black', 'asian', 'indian']\n",
        "accuracies = [w,b,a,i]\n",
        "plt.bar(labs,accuracies)\n",
        "plt.ylabel('accuracies')\n",
        "plt.title('Prediction Accuracies of Model trained only on Indian faces')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKyXOXl5_EzL"
      },
      "source": [
        "def createModel2():\n",
        "  model2 = tf.keras.models.Sequential()\n",
        "\n",
        "  model2.add(\n",
        "    layers.Conv2D(128, (8,8),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.Conv2D(64, (4,4),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.Conv2D(32, (2,2),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model2.add(\n",
        "      layers.Dropout(.2)\n",
        "  )\n",
        "  model2.add(\n",
        "    layers.Dense(64, activation = 'relu')\n",
        "  )\n",
        "  model2.add(\n",
        "      layers.Dropout(.2)\n",
        "  )\n",
        "  model2.add(\n",
        "      layers.Dense(10, activation = 'relu')\n",
        "  )\n",
        "  model2.add(\n",
        "      layers.Dropout(.2)\n",
        "  )\n",
        "## Sigmoid for binary classification\n",
        "  model2.add(\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "  )\n",
        "## Might need to change learning rate later\n",
        "  model2.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-9),\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3TqbnzBlOi"
      },
      "source": [
        "gender_model2 = createGenderModel()\n",
        "gender_model_balance2 = createGenderModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCa-QoTm_SYR"
      },
      "source": [
        "gender_model_2 = createModel2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsIseaiyA6Eb"
      },
      "source": [
        "## This is the model for gender classification\n",
        "def createGenderModel2():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(32, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "    \n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## Sigmoid for binary classification\n",
        "  model.add(\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-5),\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "## This is the model for race classification\n",
        "def createRaceModel2():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(32, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## softmax for catagorical classification(might need to change to 4 and not include other as gender)\n",
        "  model.add(\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-5),\n",
        "  loss = 'catagorical_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwNnQGExCHbJ"
      },
      "source": [
        "gender_model2 = createGenderModel2()\n",
        "gender_model_balance2 = createGenderModel2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1ePu5Ry4B65P",
        "outputId": "c63179aa-97a3-4404-b9b1-7499cf94ff64"
      },
      "source": [
        "gender_model_history_2 = gender_model2.fit(img_trn, gender_trn, epochs = 50)\n",
        "gender_model_balance_history_2 = gender_model_balance2.fit(imgTrnBalance, genderTrnBalance, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 51s 84ms/step - loss: 3.0696 - accuracy: 0.5149\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.9809 - accuracy: 0.5414\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.7874 - accuracy: 0.5671\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.7276 - accuracy: 0.5853\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.7018 - accuracy: 0.6018\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.6873 - accuracy: 0.6131\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.6726 - accuracy: 0.6266\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6607 - accuracy: 0.6391\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6466 - accuracy: 0.6572\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6411 - accuracy: 0.6568\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6376 - accuracy: 0.6688\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6336 - accuracy: 0.6768\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6201 - accuracy: 0.6827\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.6117 - accuracy: 0.6890\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6137 - accuracy: 0.6877\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.6076 - accuracy: 0.6970\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6065 - accuracy: 0.6998\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.6050 - accuracy: 0.7074\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5964 - accuracy: 0.7039\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5856 - accuracy: 0.7169\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5886 - accuracy: 0.7103\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5812 - accuracy: 0.7160\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5861 - accuracy: 0.7164\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5831 - accuracy: 0.7138\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5758 - accuracy: 0.7240\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5770 - accuracy: 0.7263\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5730 - accuracy: 0.7251\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5782 - accuracy: 0.7234\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5698 - accuracy: 0.7308\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5731 - accuracy: 0.7261\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5705 - accuracy: 0.7291\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5669 - accuracy: 0.7310\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5555 - accuracy: 0.7388\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5534 - accuracy: 0.7429\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5610 - accuracy: 0.7383\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5393 - accuracy: 0.7449\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5570 - accuracy: 0.7387\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5512 - accuracy: 0.7428\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5620 - accuracy: 0.7393\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5479 - accuracy: 0.7433\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5513 - accuracy: 0.7465\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5458 - accuracy: 0.7448\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5393 - accuracy: 0.7461\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5417 - accuracy: 0.7495\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5384 - accuracy: 0.7496\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 49s 82ms/step - loss: 0.5345 - accuracy: 0.7561\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5356 - accuracy: 0.7582\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5326 - accuracy: 0.7591\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5316 - accuracy: 0.7551\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 49s 83ms/step - loss: 0.5313 - accuracy: 0.7554\n",
            "Epoch 1/50\n",
            "339/339 [==============================] - 29s 84ms/step - loss: 5.1255 - accuracy: 0.5189\n",
            "Epoch 2/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 1.7026 - accuracy: 0.5236\n",
            "Epoch 3/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 1.2420 - accuracy: 0.5204\n",
            "Epoch 4/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 1.0343 - accuracy: 0.5276\n",
            "Epoch 5/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.9243 - accuracy: 0.5224\n",
            "Epoch 6/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.8440 - accuracy: 0.5425\n",
            "Epoch 7/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.8119 - accuracy: 0.5354\n",
            "Epoch 8/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7958 - accuracy: 0.5395\n",
            "Epoch 9/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7558 - accuracy: 0.5488\n",
            "Epoch 10/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7632 - accuracy: 0.5443\n",
            "Epoch 11/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7502 - accuracy: 0.5566\n",
            "Epoch 12/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7360 - accuracy: 0.5627\n",
            "Epoch 13/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7333 - accuracy: 0.5456\n",
            "Epoch 14/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7216 - accuracy: 0.5637\n",
            "Epoch 15/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7105 - accuracy: 0.5779\n",
            "Epoch 16/50\n",
            "339/339 [==============================] - 28s 82ms/step - loss: 0.6989 - accuracy: 0.5785\n",
            "Epoch 17/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7093 - accuracy: 0.5681\n",
            "Epoch 18/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7057 - accuracy: 0.5708\n",
            "Epoch 19/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.7024 - accuracy: 0.5799\n",
            "Epoch 20/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.6886 - accuracy: 0.5820\n",
            "Epoch 21/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.6916 - accuracy: 0.5780\n",
            "Epoch 22/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.6941 - accuracy: 0.5766\n",
            "Epoch 23/50\n",
            "339/339 [==============================] - 28s 83ms/step - loss: 0.6898 - accuracy: 0.5862\n",
            "Epoch 24/50\n",
            "133/339 [==========>...................] - ETA: 17s - loss: 0.6910 - accuracy: 0.5812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9f8f13cb004d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgender_model_history_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgender_model_balance_history_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_model_balance2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTrnBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenderTrnBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "J5qH6dUd_K9R",
        "outputId": "628f0992-6eb0-4069-fea8-b866a566fe65"
      },
      "source": [
        "\n",
        "gender_2 = gender_model_2.fit(img_trn, gender_trn, epochs = 50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 120s 147ms/step - loss: 8.9623 - accuracy: 0.4891\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 87s 147ms/step - loss: 8.6543 - accuracy: 0.4977\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 87s 147ms/step - loss: 8.9037 - accuracy: 0.4926\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 88s 148ms/step - loss: 8.4436 - accuracy: 0.4908\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 88s 148ms/step - loss: 8.4224 - accuracy: 0.5016\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 88s 148ms/step - loss: 8.3425 - accuracy: 0.4911\n",
            "Epoch 7/50\n",
            " 20/593 [>.............................] - ETA: 1:24 - loss: 8.8870 - accuracy: 0.4731"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9552b97b86ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgender_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQrjEDS6QkCk"
      },
      "source": [
        "## This is the model for gender classification\n",
        "def createGenderModel3():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5), activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3), activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## Sigmoid for binary classification\n",
        "  model.add(\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "## This is the model for race classification\n",
        "def createRaceModel3():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## softmax for catagorical classification(might need to change to 4 and not include other as gender)\n",
        "  model.add(\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'catagorical_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnQmPQTiRGNh"
      },
      "source": [
        "gender_model3 = createGenderModel3()\n",
        "gender_model_balance3 = createGenderModel3()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ObF89qevRWsl",
        "outputId": "420a4f85-b3c4-432e-c789-be7b5a82d02b"
      },
      "source": [
        "gender_model_history_3 = gender_model3.fit(img_trn, gender_trn, epochs = 50)\n",
        "gender_model_balance_history_3 = gender_model_balance3.fit(imgTrnBalance, genderTrnBalance, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 77s 127ms/step - loss: 2.4193 - accuracy: 0.5387\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.6887 - accuracy: 0.5877\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.6569 - accuracy: 0.6252\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.6332 - accuracy: 0.6503\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.6107 - accuracy: 0.6776\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5882 - accuracy: 0.6951\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5629 - accuracy: 0.7191\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5501 - accuracy: 0.7304\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5382 - accuracy: 0.7419\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5256 - accuracy: 0.7521\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.5123 - accuracy: 0.7598\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4957 - accuracy: 0.7720\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4928 - accuracy: 0.7729\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4725 - accuracy: 0.7822\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4773 - accuracy: 0.7897\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4721 - accuracy: 0.7915\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4563 - accuracy: 0.7945\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4554 - accuracy: 0.7956\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4467 - accuracy: 0.7995\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4443 - accuracy: 0.8016\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4312 - accuracy: 0.8094\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4333 - accuracy: 0.8086\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4378 - accuracy: 0.7997\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4293 - accuracy: 0.8166\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.4141 - accuracy: 0.8178\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.4179 - accuracy: 0.8199\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.4029 - accuracy: 0.8223\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.4169 - accuracy: 0.8167\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.4076 - accuracy: 0.8221\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3972 - accuracy: 0.8263\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3944 - accuracy: 0.8282\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3887 - accuracy: 0.8304\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3979 - accuracy: 0.8239\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3883 - accuracy: 0.8273\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3906 - accuracy: 0.8249\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3865 - accuracy: 0.8333\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3784 - accuracy: 0.8362\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3822 - accuracy: 0.8336\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3735 - accuracy: 0.8336\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3708 - accuracy: 0.8403\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3641 - accuracy: 0.8431\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3708 - accuracy: 0.8436\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3658 - accuracy: 0.8412\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3693 - accuracy: 0.8422\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 74s 125ms/step - loss: 0.3598 - accuracy: 0.8398\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 74s 126ms/step - loss: 0.3593 - accuracy: 0.8426\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3593 - accuracy: 0.8426\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3582 - accuracy: 0.8407\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3606 - accuracy: 0.8431\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 75s 126ms/step - loss: 0.3606 - accuracy: 0.8460\n",
            "Epoch 1/50\n",
            "339/339 [==============================] - 44s 127ms/step - loss: 2.6046 - accuracy: 0.5335\n",
            "Epoch 2/50\n",
            "339/339 [==============================] - 43s 127ms/step - loss: 0.7331 - accuracy: 0.5418\n",
            "Epoch 3/50\n",
            "339/339 [==============================] - 43s 126ms/step - loss: 0.7062 - accuracy: 0.5624\n",
            "Epoch 4/50\n",
            "339/339 [==============================] - 43s 127ms/step - loss: 0.6859 - accuracy: 0.5693\n",
            "Epoch 5/50\n",
            "339/339 [==============================] - 43s 127ms/step - loss: 0.6866 - accuracy: 0.5730\n",
            "Epoch 6/50\n",
            "339/339 [==============================] - 43s 126ms/step - loss: 0.6716 - accuracy: 0.5986\n",
            "Epoch 7/50\n",
            "339/339 [==============================] - 43s 126ms/step - loss: 0.6692 - accuracy: 0.6035\n",
            "Epoch 8/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6626 - accuracy: 0.6194\n",
            "Epoch 9/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6512 - accuracy: 0.6317\n",
            "Epoch 10/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6523 - accuracy: 0.6301\n",
            "Epoch 11/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6428 - accuracy: 0.6483\n",
            "Epoch 12/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6357 - accuracy: 0.6531\n",
            "Epoch 13/50\n",
            "339/339 [==============================] - 43s 126ms/step - loss: 0.6298 - accuracy: 0.6574\n",
            "Epoch 14/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6292 - accuracy: 0.6665\n",
            "Epoch 15/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6260 - accuracy: 0.6635\n",
            "Epoch 16/50\n",
            "339/339 [==============================] - 43s 126ms/step - loss: 0.6170 - accuracy: 0.6795\n",
            "Epoch 17/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6189 - accuracy: 0.6796\n",
            "Epoch 18/50\n",
            "339/339 [==============================] - 42s 125ms/step - loss: 0.6103 - accuracy: 0.7000\n",
            "Epoch 19/50\n",
            " 49/339 [===>..........................] - ETA: 36s - loss: 0.6236 - accuracy: 0.6834"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8ee0a1a39eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgender_model_history_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_model3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgender_model_balance_history_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_model_balance3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTrnBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenderTrnBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwSAeAv5i4Ae"
      },
      "source": [
        "from tensorflow.python.keras import regularizers"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Eajx2OhhmB"
      },
      "source": [
        "## This is the model for gender classification\n",
        "def createGenderModel4():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu', kernel_regularizer = regularizers.l2(l=0.01))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu',kernel_regularizer = regularizers.l2(l=0.01))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu',kernel_regularizer = regularizers.l2(l=0.01))\n",
        "  )\n",
        "  ## Sigmoid for binary classification\n",
        "  model.add(\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "## This is the model for race classification\n",
        "def createRaceModel4():\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "    layers.Conv2D(64, (5,5),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (200,200,3))\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Conv2D(128, (3,3),\n",
        "                  activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.SpatialDropout2D(.5)\n",
        "  )\n",
        "  model.add(\n",
        "    layers.MaxPooling2D((2,2))\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Flatten()\n",
        "  )\n",
        "  model.add(\n",
        "    layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  model.add(\n",
        "      layers.Dense(128, activation = 'relu')\n",
        "  )\n",
        "  ## softmax for catagorical classification(might need to change to 4 and not include other as gender)\n",
        "  model.add(\n",
        "    layers.Dense(5, activation = 'softmax')\n",
        "  )\n",
        "  ## Might need to change learning rate later\n",
        "  model.compile(\n",
        "  optimizer = optimizers.SGD(learning_rate=1e-4),\n",
        "  loss = 'categorical_crossentropy',\n",
        "  metrics = ['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrFwDjJipUn"
      },
      "source": [
        "gender_model4 = createGenderModel4()\n",
        "gender_model_balance4 = createGenderModel4()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRgSVOjjBF7",
        "outputId": "adf89f00-934a-4376-dcc3-42538eebf1be"
      },
      "source": [
        "gender_model_history_4 = gender_model4.fit(img_trn, gender_trn, epochs = 50)\n",
        "gender_model_balance_history_4 = gender_model_balance4.fit(imgTrnBalance, genderTrnBalance, epochs = 50)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 45s 49ms/step - loss: 7.2443 - accuracy: 0.5704\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.2438 - accuracy: 0.7254\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.1654 - accuracy: 0.7736\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.1224 - accuracy: 0.8012\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.0735 - accuracy: 0.8170\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.0455 - accuracy: 0.8264\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 5.0189 - accuracy: 0.8306\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9870 - accuracy: 0.8434\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9691 - accuracy: 0.8491\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9484 - accuracy: 0.8505\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9385 - accuracy: 0.8496\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9102 - accuracy: 0.8554\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.9029 - accuracy: 0.8572\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8788 - accuracy: 0.8626\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8615 - accuracy: 0.8676\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8509 - accuracy: 0.8637\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8279 - accuracy: 0.8692\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8185 - accuracy: 0.8693\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.8059 - accuracy: 0.8693\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7895 - accuracy: 0.8754\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7678 - accuracy: 0.8754\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7580 - accuracy: 0.8800\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7440 - accuracy: 0.8795\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7299 - accuracy: 0.8854\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.7156 - accuracy: 0.8813\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.7053 - accuracy: 0.8851\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6933 - accuracy: 0.8839\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6679 - accuracy: 0.8906\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6595 - accuracy: 0.8901\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6560 - accuracy: 0.8917\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6452 - accuracy: 0.8880\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6314 - accuracy: 0.8865\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.6197 - accuracy: 0.8886\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.6038 - accuracy: 0.8942\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.5900 - accuracy: 0.8928\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.5780 - accuracy: 0.8953\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.5644 - accuracy: 0.8977\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.5486 - accuracy: 0.8963\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.5408 - accuracy: 0.8986\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.5321 - accuracy: 0.8954\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.5108 - accuracy: 0.9015\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.4953 - accuracy: 0.9050\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.4969 - accuracy: 0.9017\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.4741 - accuracy: 0.9061\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.4707 - accuracy: 0.9054\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 28s 48ms/step - loss: 4.4591 - accuracy: 0.9043\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.4522 - accuracy: 0.8978\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 29s 49ms/step - loss: 4.4395 - accuracy: 0.9034\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 29s 49ms/step - loss: 4.4227 - accuracy: 0.9063\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 29s 48ms/step - loss: 4.4128 - accuracy: 0.9082\n",
            "Epoch 1/50\n",
            "339/339 [==============================] - 17s 48ms/step - loss: 8.6536 - accuracy: 0.5427\n",
            "Epoch 2/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.3326 - accuracy: 0.6415\n",
            "Epoch 3/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.3032 - accuracy: 0.6679\n",
            "Epoch 4/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.2624 - accuracy: 0.7040\n",
            "Epoch 5/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.2509 - accuracy: 0.7102\n",
            "Epoch 6/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.2253 - accuracy: 0.7271\n",
            "Epoch 7/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.2203 - accuracy: 0.7265\n",
            "Epoch 8/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1927 - accuracy: 0.7470\n",
            "Epoch 9/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1859 - accuracy: 0.7482\n",
            "Epoch 10/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1696 - accuracy: 0.7524\n",
            "Epoch 11/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1586 - accuracy: 0.7648\n",
            "Epoch 12/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1499 - accuracy: 0.7607\n",
            "Epoch 13/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1412 - accuracy: 0.7555\n",
            "Epoch 14/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1191 - accuracy: 0.7690\n",
            "Epoch 15/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1225 - accuracy: 0.7639\n",
            "Epoch 16/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.1110 - accuracy: 0.7715\n",
            "Epoch 17/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0924 - accuracy: 0.7770\n",
            "Epoch 18/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0908 - accuracy: 0.7743\n",
            "Epoch 19/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0816 - accuracy: 0.7676\n",
            "Epoch 20/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0610 - accuracy: 0.7850\n",
            "Epoch 21/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0636 - accuracy: 0.7779\n",
            "Epoch 22/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0541 - accuracy: 0.7801\n",
            "Epoch 23/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0360 - accuracy: 0.7853\n",
            "Epoch 24/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0246 - accuracy: 0.7907\n",
            "Epoch 25/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0320 - accuracy: 0.7816\n",
            "Epoch 26/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0212 - accuracy: 0.7845\n",
            "Epoch 27/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 5.0070 - accuracy: 0.7874\n",
            "Epoch 28/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9910 - accuracy: 0.7980\n",
            "Epoch 29/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9932 - accuracy: 0.7921\n",
            "Epoch 30/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9949 - accuracy: 0.7893\n",
            "Epoch 31/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9789 - accuracy: 0.7909\n",
            "Epoch 32/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9657 - accuracy: 0.7937\n",
            "Epoch 33/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9645 - accuracy: 0.7884\n",
            "Epoch 34/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9555 - accuracy: 0.7902\n",
            "Epoch 35/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9390 - accuracy: 0.7984\n",
            "Epoch 36/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9372 - accuracy: 0.7945\n",
            "Epoch 37/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9113 - accuracy: 0.8053\n",
            "Epoch 38/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9199 - accuracy: 0.7989\n",
            "Epoch 39/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9113 - accuracy: 0.8036\n",
            "Epoch 40/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.9021 - accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8797 - accuracy: 0.8086\n",
            "Epoch 42/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8887 - accuracy: 0.8011\n",
            "Epoch 43/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8724 - accuracy: 0.8090\n",
            "Epoch 44/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8614 - accuracy: 0.8140\n",
            "Epoch 45/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8614 - accuracy: 0.8087\n",
            "Epoch 46/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8536 - accuracy: 0.8084\n",
            "Epoch 47/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8458 - accuracy: 0.8055\n",
            "Epoch 48/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8407 - accuracy: 0.8030\n",
            "Epoch 49/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8238 - accuracy: 0.8134\n",
            "Epoch 50/50\n",
            "339/339 [==============================] - 16s 48ms/step - loss: 4.8247 - accuracy: 0.8069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG9z2iMgBnHh"
      },
      "source": [
        "y_pred4 = gender_model4.predict(img_tst)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sinQqZ5cEBES"
      },
      "source": [
        "pred = list()\n",
        "for i in range(y_pred4):\n",
        "  pred.append(np.argmax(y_pred4[i]))\n",
        "test = list()\n",
        "for i in range(len())\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "#Converting predictions to label\n",
        "pred = list()\n",
        "for i in range(len(y_pred)):\n",
        "    pred.append(np.argmax(y_pred[i]))\n",
        "#Converting one hot encoded test label to label\n",
        "test = list()\n",
        "for i in range(len(y_test)):\n",
        "    test.append(np.argmax(y_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2-LmV0YGIn5"
      },
      "source": [
        "predict_4 = list()\n",
        "for i in range(len(y_pred4)):\n",
        "  if y_pred4[i] > 0.5:\n",
        "    predict_4.append(1)\n",
        "  else:\n",
        "    predict_4.append(0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH-PlsZuIF7Q",
        "outputId": "2e12ff23-8f41-4c84-d969-3e880b1c705f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(predict_4, gender_tst)\n",
        "print(a*100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88.39907192575406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suo6P83U5-gD",
        "outputId": "a33f3103-61ce-43fd-ae63-9a4a1404ac02"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(gender_tst, predict_4))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      2414\n",
            "           1       0.88      0.88      0.88      2327\n",
            "\n",
            "    accuracy                           0.88      4741\n",
            "   macro avg       0.88      0.88      0.88      4741\n",
            "weighted avg       0.88      0.88      0.88      4741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "n4qMYgZV-Db4",
        "outputId": "8e5e59e1-7bfe-4c3c-f141-2473f609bc56"
      },
      "source": [
        "plt.plot(gender_model_history_4.history['loss'])\n",
        "plt.title(\"Full Gender Model Loss from Binary Cross Entropy Loss Function\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkXxaSFpJ8IC"
      },
      "source": [
        "race_model4 = createRaceModel4()\n",
        "race_model_balance4 = createRaceModel4()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8zbfAUxZE8X",
        "outputId": "cf710beb-3020-4bef-ee27-d476b86cdc47"
      },
      "source": [
        "full_race_race = tf.keras.utils.to_categorical(races_trn)\n",
        "trn_race_balance = tf.keras.utils.to_categorical(raceTrnBalance)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 49,  53,  48],\n",
              "         [ 48,  52,  47],\n",
              "         [ 48,  52,  47],\n",
              "         ...,\n",
              "         [ 65,  73,  72],\n",
              "         [ 66,  74,  73],\n",
              "         [ 66,  74,  73]],\n",
              "\n",
              "        [[ 48,  52,  47],\n",
              "         [ 47,  51,  46],\n",
              "         [ 47,  51,  46],\n",
              "         ...,\n",
              "         [ 65,  73,  72],\n",
              "         [ 66,  74,  73],\n",
              "         [ 66,  74,  73]],\n",
              "\n",
              "        [[ 46,  50,  45],\n",
              "         [ 46,  50,  45],\n",
              "         [ 46,  50,  45],\n",
              "         ...,\n",
              "         [ 65,  73,  72],\n",
              "         [ 66,  74,  73],\n",
              "         [ 65,  73,  72]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 62,  75,  77],\n",
              "         [ 62,  75,  77],\n",
              "         [ 59,  74,  76],\n",
              "         ...,\n",
              "         [ 69,  82,  90],\n",
              "         [ 68,  81,  89],\n",
              "         [ 68,  81,  89]],\n",
              "\n",
              "        [[ 62,  75,  77],\n",
              "         [ 62,  75,  77],\n",
              "         [ 59,  74,  76],\n",
              "         ...,\n",
              "         [ 70,  83,  91],\n",
              "         [ 68,  81,  89],\n",
              "         [ 68,  81,  89]],\n",
              "\n",
              "        [[ 62,  75,  77],\n",
              "         [ 62,  75,  77],\n",
              "         [ 59,  74,  76],\n",
              "         ...,\n",
              "         [ 70,  83,  91],\n",
              "         [ 68,  81,  89],\n",
              "         [ 67,  80,  88]]],\n",
              "\n",
              "\n",
              "       [[[ 52,  58,  81],\n",
              "         [ 51,  57,  80],\n",
              "         [ 49,  56,  76],\n",
              "         ...,\n",
              "         [ 19,  28,  48],\n",
              "         [ 26,  35,  55],\n",
              "         [ 40,  49,  69]],\n",
              "\n",
              "        [[ 51,  57,  80],\n",
              "         [ 50,  56,  79],\n",
              "         [ 48,  55,  75],\n",
              "         ...,\n",
              "         [ 19,  28,  48],\n",
              "         [ 30,  39,  59],\n",
              "         [ 48,  57,  77]],\n",
              "\n",
              "        [[ 51,  57,  80],\n",
              "         [ 48,  54,  77],\n",
              "         [ 45,  52,  72],\n",
              "         ...,\n",
              "         [ 19,  28,  48],\n",
              "         [ 37,  46,  66],\n",
              "         [ 58,  67,  87]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 42,  43,  57],\n",
              "         [ 43,  44,  58],\n",
              "         [ 43,  46,  61],\n",
              "         ...,\n",
              "         [ 27,  27,  27],\n",
              "         [ 35,  35,  35],\n",
              "         [ 40,  40,  40]],\n",
              "\n",
              "        [[ 46,  46,  58],\n",
              "         [ 44,  46,  57],\n",
              "         [ 42,  45,  59],\n",
              "         ...,\n",
              "         [ 24,  24,  24],\n",
              "         [ 32,  32,  32],\n",
              "         [ 37,  37,  37]],\n",
              "\n",
              "        [[ 48,  48,  60],\n",
              "         [ 45,  47,  58],\n",
              "         [ 44,  45,  59],\n",
              "         ...,\n",
              "         [ 16,  16,  16],\n",
              "         [ 22,  22,  22],\n",
              "         [ 26,  26,  26]]],\n",
              "\n",
              "\n",
              "       [[[241, 246, 247],\n",
              "         [240, 245, 246],\n",
              "         [239, 244, 245],\n",
              "         ...,\n",
              "         [181, 197, 213],\n",
              "         [183, 199, 215],\n",
              "         [184, 200, 216]],\n",
              "\n",
              "        [[240, 245, 246],\n",
              "         [239, 244, 245],\n",
              "         [239, 244, 245],\n",
              "         ...,\n",
              "         [180, 196, 212],\n",
              "         [182, 198, 214],\n",
              "         [183, 199, 215]],\n",
              "\n",
              "        [[239, 244, 245],\n",
              "         [238, 243, 244],\n",
              "         [238, 243, 244],\n",
              "         ...,\n",
              "         [179, 195, 211],\n",
              "         [181, 197, 213],\n",
              "         [182, 198, 214]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         ...,\n",
              "         [107, 129, 117],\n",
              "         [124, 141, 130],\n",
              "         [135, 152, 141]],\n",
              "\n",
              "        [[243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         ...,\n",
              "         [108, 130, 118],\n",
              "         [125, 142, 131],\n",
              "         [137, 154, 143]],\n",
              "\n",
              "        [[243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         [243, 234, 224],\n",
              "         ...,\n",
              "         [107, 129, 117],\n",
              "         [124, 141, 130],\n",
              "         [135, 152, 141]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 39,  54,  93],\n",
              "         [ 39,  54,  93],\n",
              "         [ 39,  54,  93],\n",
              "         ...,\n",
              "         [  5,   5,   5],\n",
              "         [  5,   5,   5],\n",
              "         [  5,   5,   5]],\n",
              "\n",
              "        [[ 38,  53,  92],\n",
              "         [ 38,  53,  92],\n",
              "         [ 38,  53,  92],\n",
              "         ...,\n",
              "         [  5,   5,   5],\n",
              "         [  5,   5,   5],\n",
              "         [  5,   5,   5]],\n",
              "\n",
              "        [[ 37,  52,  91],\n",
              "         [ 37,  52,  91],\n",
              "         [ 37,  52,  91],\n",
              "         ...,\n",
              "         [  4,   4,   4],\n",
              "         [  5,   5,   5],\n",
              "         [  5,   5,   5]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[108, 142, 202],\n",
              "         [108, 142, 202],\n",
              "         [108, 142, 202],\n",
              "         ...,\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15]],\n",
              "\n",
              "        [[109, 143, 203],\n",
              "         [109, 143, 203],\n",
              "         [109, 143, 203],\n",
              "         ...,\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15]],\n",
              "\n",
              "        [[110, 144, 204],\n",
              "         [110, 144, 204],\n",
              "         [110, 144, 204],\n",
              "         ...,\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15],\n",
              "         [ 14,  13,  15]]],\n",
              "\n",
              "\n",
              "       [[[ 70,  57,  59],\n",
              "         [ 72,  59,  61],\n",
              "         [ 73,  62,  64],\n",
              "         ...,\n",
              "         [100,  87,  95],\n",
              "         [110,  98, 104],\n",
              "         [119, 108, 111]],\n",
              "\n",
              "        [[ 70,  57,  59],\n",
              "         [ 72,  59,  61],\n",
              "         [ 73,  62,  64],\n",
              "         ...,\n",
              "         [109,  96, 104],\n",
              "         [120, 108, 114],\n",
              "         [128, 117, 120]],\n",
              "\n",
              "        [[ 70,  56,  58],\n",
              "         [ 72,  59,  61],\n",
              "         [ 73,  62,  64],\n",
              "         ...,\n",
              "         [122, 109, 117],\n",
              "         [133, 121, 127],\n",
              "         [142, 131, 134]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         ...,\n",
              "         [ 77,  70,  75],\n",
              "         [ 78,  71,  76],\n",
              "         [ 79,  72,  77]],\n",
              "\n",
              "        [[ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         ...,\n",
              "         [ 77,  70,  75],\n",
              "         [ 78,  71,  76],\n",
              "         [ 79,  72,  77]],\n",
              "\n",
              "        [[ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         [ 66,  53,  61],\n",
              "         ...,\n",
              "         [ 77,  70,  75],\n",
              "         [ 78,  71,  76],\n",
              "         [ 79,  72,  77]]],\n",
              "\n",
              "\n",
              "       [[[246, 243, 239],\n",
              "         [243, 240, 236],\n",
              "         [241, 238, 234],\n",
              "         ...,\n",
              "         [ 80,  78,  77],\n",
              "         [103, 101, 100],\n",
              "         [127, 125, 124]],\n",
              "\n",
              "        [[247, 244, 240],\n",
              "         [244, 241, 237],\n",
              "         [242, 239, 235],\n",
              "         ...,\n",
              "         [ 78,  76,  75],\n",
              "         [101,  99,  98],\n",
              "         [125, 123, 122]],\n",
              "\n",
              "        [[248, 245, 241],\n",
              "         [245, 242, 238],\n",
              "         [242, 239, 235],\n",
              "         ...,\n",
              "         [ 74,  75,  73],\n",
              "         [ 97,  95,  94],\n",
              "         [121, 119, 118]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         ...,\n",
              "         [181, 156, 140],\n",
              "         [180, 155, 139],\n",
              "         [180, 155, 139]],\n",
              "\n",
              "        [[247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         ...,\n",
              "         [184, 156, 139],\n",
              "         [184, 156, 139],\n",
              "         [182, 156, 139]],\n",
              "\n",
              "        [[247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         [247, 246, 232],\n",
              "         ...,\n",
              "         [185, 155, 138],\n",
              "         [184, 156, 139],\n",
              "         [185, 157, 140]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eblO_DC0KHxB",
        "outputId": "fba9adce-3453-4984-f542-1e68ea73fd2a"
      },
      "source": [
        "\n",
        "race_model_history_4 = race_model4.fit(img_trn, full_race_race, epochs = 50)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 7.7071 - accuracy: 0.3108\n",
            "Epoch 2/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 1.3390 - accuracy: 0.4883\n",
            "Epoch 3/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 1.1761 - accuracy: 0.5676\n",
            "Epoch 4/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 1.0832 - accuracy: 0.6160\n",
            "Epoch 5/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 1.0066 - accuracy: 0.6487\n",
            "Epoch 6/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.9773 - accuracy: 0.6570\n",
            "Epoch 7/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.9518 - accuracy: 0.6614\n",
            "Epoch 8/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.9135 - accuracy: 0.6778\n",
            "Epoch 9/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.9222 - accuracy: 0.6834\n",
            "Epoch 10/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.8871 - accuracy: 0.6926\n",
            "Epoch 11/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.8616 - accuracy: 0.7019\n",
            "Epoch 12/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.8468 - accuracy: 0.7065\n",
            "Epoch 13/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.8308 - accuracy: 0.7123\n",
            "Epoch 14/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.8275 - accuracy: 0.7106\n",
            "Epoch 15/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.8075 - accuracy: 0.7214\n",
            "Epoch 16/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7973 - accuracy: 0.7244\n",
            "Epoch 17/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7771 - accuracy: 0.7318\n",
            "Epoch 18/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7725 - accuracy: 0.7336\n",
            "Epoch 19/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7695 - accuracy: 0.7321\n",
            "Epoch 20/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7568 - accuracy: 0.7369\n",
            "Epoch 21/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7442 - accuracy: 0.7395\n",
            "Epoch 22/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7389 - accuracy: 0.7434\n",
            "Epoch 23/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7432 - accuracy: 0.7429\n",
            "Epoch 24/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7185 - accuracy: 0.7485\n",
            "Epoch 25/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7114 - accuracy: 0.7504\n",
            "Epoch 26/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7169 - accuracy: 0.7480\n",
            "Epoch 27/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.7109 - accuracy: 0.7527\n",
            "Epoch 28/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6964 - accuracy: 0.7624\n",
            "Epoch 29/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6935 - accuracy: 0.7599\n",
            "Epoch 30/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.6727 - accuracy: 0.7724\n",
            "Epoch 31/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6706 - accuracy: 0.7683\n",
            "Epoch 32/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.6650 - accuracy: 0.7724\n",
            "Epoch 33/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.6704 - accuracy: 0.7657\n",
            "Epoch 34/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.6478 - accuracy: 0.7748\n",
            "Epoch 35/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.6500 - accuracy: 0.7754\n",
            "Epoch 36/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6465 - accuracy: 0.7766\n",
            "Epoch 37/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6293 - accuracy: 0.7826\n",
            "Epoch 38/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6222 - accuracy: 0.7842\n",
            "Epoch 39/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6184 - accuracy: 0.7849\n",
            "Epoch 40/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6063 - accuracy: 0.7884\n",
            "Epoch 41/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6167 - accuracy: 0.7844\n",
            "Epoch 42/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.5975 - accuracy: 0.7923\n",
            "Epoch 43/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.6009 - accuracy: 0.7919\n",
            "Epoch 44/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.5945 - accuracy: 0.7979\n",
            "Epoch 45/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.5951 - accuracy: 0.7943\n",
            "Epoch 46/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.5701 - accuracy: 0.8024\n",
            "Epoch 47/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.5769 - accuracy: 0.7997\n",
            "Epoch 48/50\n",
            "593/593 [==============================] - 27s 45ms/step - loss: 0.5725 - accuracy: 0.7950\n",
            "Epoch 49/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.5725 - accuracy: 0.8010\n",
            "Epoch 50/50\n",
            "593/593 [==============================] - 27s 46ms/step - loss: 0.5594 - accuracy: 0.8027\n",
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d1e67e0573a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrace_model_history_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrace_model4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_race_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrace_model_balance_history_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrace_model_balance4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTrnBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_race_balance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 4) and (None, 5) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "801MmjuZhJ2h"
      },
      "source": [
        "y_pred4_race = race_model4.predict(img_tst)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0LQZ5_Di5iA",
        "outputId": "e99b115b-4f6d-4f6c-ca0d-112c0953b7ba"
      },
      "source": [
        "i = y_pred4_race[1]\n",
        "print(i)\n",
        "checker = np.argmax(i)\n",
        "print(checker)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5470276  0.00867056 0.02180126 0.05041581 0.3720848 ]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuLKNADzkXRx"
      },
      "source": [
        "predict_4_race = list()\n",
        "for i in range(len(y_pred4_race)):\n",
        "  largest_arg = np.argmax(y_pred4_race[i])\n",
        "  predict_4_race.append(largest_arg)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQMXWDNckpfG",
        "outputId": "27852314-cf3e-4450-b989-0bed54f9466a"
      },
      "source": [
        "a2 = accuracy_score(predict_4_race, races_tst)\n",
        "print(a2*100)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74.94199535962876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmXe972E6zc7",
        "outputId": "3ba08ed4-cc5d-418f-fec0-f8f98fbbd145"
      },
      "source": [
        "print(classification_report(races_tst, predict_4_race))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83      1987\n",
            "           1       0.84      0.77      0.80       874\n",
            "           2       0.89      0.70      0.79       728\n",
            "           3       0.70      0.67      0.69       803\n",
            "           4       0.27      0.34      0.30       349\n",
            "\n",
            "    accuracy                           0.75      4741\n",
            "   macro avg       0.70      0.67      0.68      4741\n",
            "weighted avg       0.76      0.75      0.75      4741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "4RBK0gaUB-z_",
        "outputId": "9ac8518a-af0c-4326-b4a7-664d500a3e77"
      },
      "source": [
        "plt.plot(race_model_history_4.history['loss'])\n",
        "plt.title(\"Full Race Model Loss from Categorical Cross Entropy Loss Function\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}